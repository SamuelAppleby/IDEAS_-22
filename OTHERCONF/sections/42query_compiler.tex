\subsection{Query Compiler}\label{sec:qc}
The query compiler is structured into three main phases. \textit{(i)} The \textit{atomization pipeline}  rewrites the data predicates 
associated to each activity label as a 
disjunction of mutually exclusive data conditions. We can tune KnoBAB by always atomizing each possible activity label if it exists any Declare Constraint associating it to a data condition as in \cite{bpm21}, or we can choose to provide such an interval decomposition only to the Declare constraints exhibiting data conditions. While the former approach will maximise the access to the \textsf{AttributeTable}s, the latter will maximise the access to the \textsf{ActTable}. By doing so, we can ensure that the data satisfying some given properties can be visited at most once, thus guaranteeting the assumptions from \cite{BellatrecheKB21} also at the data accessing level. Correlation conditions do not undergo this rewriting step. The atomized model in \figurename~\ref{fig:knobab_pipeline} replaces the non-correlation data predicates with the outcome of the atomization process as in \cite{bpm21}. 

%<<<<<<< HEAD
%<<<<<<< HEAD
%\textit{Second}, we rewrite each Declare constraint as a \xLTLf formula, where the activations (and the potential target) conditions are instantiated with either just activity labels or also with associated data conditions as per previous atomization step. This step is mediated through a configuration file loaded at warm-up time, where novel declare constraints can be expressed as \xLTLf formulae. We guarantee to represent each subquery at most once as in \cite{BellatrecheKB21} by representing each node in the query plan at most once: this is ensured by an internal cache. At the end of this process, the query plan considering the simultaneous execution of multiple queries can be represented as a \textsc{Direct Acyclic Graph} (DAG).  For each declarative clause appearing $m$ times within the model where $m>1$, the associated computation will be only run once and then its data is going to be associated to all of the \xLTLf formula roots within the DAG. \texttt{\color{red}[TODO: link to the infographic picture, continue the use case example. Potentially expand the description if something is not self-evident from the pictures]}
%=======
%\textit{Second}, we rewrite each Declare constraint as a \xLTLf formula, where the activations (and the potential target) conditions are instantiated with either just activity labels or also with associated data conditions as per previous atomization step. This step is mediated through a configuration file loaded at warm-up time, where novel declare constraints can be expressed as \xLTLf formulae. We guarantee to represent each subquery at most once as in \cite{BellatrecheKB21} by representing each node in the query plan at most once: this is ensured by an internal cache. At the end of this process, the query plan considering the simultaneous execution of multiple queries can be represented as a \textsc{Direct Acyclic Graph} (DAG). 
%>>>>>>> 3a6e4d5b1f0a9d9f27e0e9f9588e3f0f743bda2c
%=======
%<<<<<<< nosam
We \textit{(ii)} rewrite each Declare constraint as a \xLTLf formula, where the activations (and the potential target) conditions are instantiated with either just activity labels or also with associated data conditions as per previous atomization step. This step is mediated through a configuration file loaded at warm-up time, where novel declare constraints can be expressed as \xLTLf formulae. We guarantee to represent each subquery at most once as in \cite{BellatrecheKB21} by representing each node in the query plan at most once: this is ensured by an internal query manager cache. At the end of this process, the query plan considering the simultaneous execution of multiple queries can be represented as a \textsc{Direct Acyclic Graph} (DAG).  
For each declarative clause appearing more than once (e.g., $m>1$), the associated \xLTLf expression will be computed at most run once, while its resulting data is going to be accessed $m$ times by the final aggregator: \figurename~\ref{fig:knobab_pipeline} shows that, despite \textsc{Response} might be considered a subquery of \textsc{Succession}, the Max-SAT is still going to retrieve the output provided by the associated sub-expression. Green arrows remark operators' output shared among operators. Please also observe that operators with the same name and arguments but marked either with activation, target, or no specification are considered different as they provide different results, and therefore are not merged together. %\texttt{\color{red}[TODO: link to the infographic picture, continue the use case example. Potentially expand the description if something is not self-evident from the pictures]}
%=======
%\textit{Second}, we rewrite each Declare constraint as a \xLTLf formula, where the activations (and the potential target) conditions are instantiated with either just activity labels or also with associated data conditions as per previous atomization step. This step is mediated through a configuration file loaded at warm-up time, where novel declare constraints can be expressed as \xLTLf formulae. We guarantee to represent each subquery at most once as in \cite{BellatrecheKB21} by representing each node in the query plan at most once: this is ensured by an internal cache. At the end of this process, the query plan considering the simultaneous execution of multiple queries can be represented as a \textsc{Direct Acyclic Graph} (DAG). 
%>>>>>>> main
%>>>>>>> b69bdd98c4f898e5f4801fc44cbae460ecd04aef

Given that our execution engine provides the possibility of running a query plan in either a parallel or in a sequential mode, we need   an additional step. \textit{(iii)} The DAG returned by the previous step represents a dependency graph, where a link between a ancestor and one of its descendants implies that the latter has to be computed before the former, thus suggesting an execution order. \figurename~\ref{fig:knobab_pipeline} depicts this as an arrow starting from the ancestor. To enforce that, we perform a lexicographical order over the DAG, through which we compute the maximum depth level associated to each node of the graph. After doing so, we represent the query graph as a stack of layers, consisting of several different operators represented in an array. After this stage, each operator within such an array can be executed in parallel alongside its layer siblings. This proves that the computation of Declare Clauses can be reduced into an embarrassingly parallel problem, as the layered execution guarantees that no thread communication needs to happen, and that multiple threads could access contemporary the partial results associated to the immediately-descendant operators. Furthermore, the proposed parallelization ensures to minimize the data access for computing the query. The graph \figurename~\ref{fig:knobab_pipeline}, is the Query Plan associated to the atomized model that is going to be run by te execution engine.
