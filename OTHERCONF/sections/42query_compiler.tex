\subsection{Query Compiler}\label{sec:qc}
The query compiler is structured into three main phases. \textit{First}, we rewrite the data predicates 
associated to each activity label as a 
disjunction of mutually exclusive data conditions. We can tune KnoBAB by always atomizing each possible activity label if it exists any Declare Constraint associating it to a data condition as in \cite{bpm21}, or we can choose to provide such an interval decomposition only to the Declare constraints exhibiting data conditions. While the former approach will maximise the access to the \textsf{AttributeTable}s, the latter will maximise the access to the \textsf{ActTable}. By doing so, we can ensure that the data satisfying some given properties can be visited at most once, thus guaranteeting the assumptions from \cite{BellatrecheKB21} also at the data accessing level. Correlation conditions do not undergo this rewriting step. From \figurename\ref{fig:knobab_pipeline}, the Atomized model contains the outcome from the atomization of the data predicated associated with $\mathcal{M}$ as in \cite{bpm21}. $\mathcal{M}$ contains the instantiated decomposition for each declare clause.

\textit{Second}, we rewrite each Declare constraint as a \xLTLf formula, where the activations (and the potential target) conditions are instantiated with either just activity labels or also with associated data conditions as per previous atomization step. This step is mediated through a configuration file loaded at warm-up time, where novel declare constraints can be expressed as \xLTLf formulae. We guarantee to represent each subquery at most once as in \cite{BellatrecheKB21} by representing each node in the query plan at most once: this is ensured by an internal cache. At the end of this process, the query plan considering the simultaneous execution of multiple queries can be represented as a \textsc{Direct Acyclic Graph} (DAG). 

Given that our execution engine provides the possibility of running a query plan in either a parallel or in a sequential mode, we need   an additional \textit{Third} computational step. The DAG returned by the previous step represents a dependency graph, where a link between a parent and an ancestor operator implies that the latter has to be computed before the former, thus suggesting an execution order. To enforce that, we perform a lexicographical order over the DAG, through which we compute the maximum depth level associated to each node of the graph. After doing so, we represent the query graph as a stack of layers, consisting of several different operators represented in an array. After this stage, each operator within such an array can be executed in parallel alongside its layer siblings. This proves that the computation of Declare Clauses can be reduced into an embarrassingly parallel problem, as the layered execution guarantees that no thread communication needs to happen, and that multiple threads could access contemporary the partial results associated to the immediately-descendant operators. Furthermore, the proposed parallelization ensures to minimize the data access for computing the query. The graph \figurename\ref{fig:knobab_pipeline}, is the Query Plan associated to the atomized model that is going to be run by te execution engine.
