\subsection{Query Compiler}
The query compiler is structured into four main phases. \textit{First}, we decompose the data predicates associated to each activity label so that each data predicate can be rewritten as a disjunction of mutually exclusive data conditions. Still, we can tune KnoBAB by always atomizing each possible activity label if it exists any Declare Constraint associating it to a data condition as in \cite{bpm21}, or we can choose to provide such an interval decomposition only to the Declare constraints exhibiting data conditions. While the former approach will maximise the access to the \textsf{AttributeTable}s, the latter will maximise the access to the \textsf{ActTable}. By doing so, we can ensure that the data satisfying some given properties can be visited at most once, thus guaranteeting the assumptions from \cite{BellatrecheKB21} also at the data accessing level, and can test our pipeline on different algorithmic assumptions. \texttt{\color{red}[TODO: link to the infographic picture, continue the use case example]}

\textit{Second}, we rewrite each Declare constraint as a set of \xLTLf operators, where the activations (and the potential target) conditions are instantiated as per previous atomization step. This step is mediated through a configuration file loaded at warm-up time, where novel declare constraints can be expressed as combination of such operators. We guarantee to represent each subquery at most once as in \cite{BellatrecheKB21} by guaraneeting to represent each node at most once via a query cache system guaranteeting not to re-allocate already-instantiated nodes. At the end of this process, the query plan considering the simultaneous execution of multiple queries can be represented as a \textsc{Direct Acyclic Graph}.  \texttt{\color{red}[TODO: link to the infographic picture, continue the use case example. Potentially expand the description if something is not self-evident from the pictures]}

Given that our execution engine provides the possibility of running a query plan in either a parallel or in a sequential mode, we need to perform an additional \textit{Third} computation step over the generated query plan. In fact, the graph returned by the previous step represents a dependency graph, where the link between a parent and an ancestor operator implies that the latter has to be computed before the latter, thus suggesting an execution order. In order to enforce that, we perform a lexicographical order over such a graph, through which we compute the maximum depth level associated to each node of the graph. After doing so, we represent the query graph as a stack of layers, where each layer might be composed of several different operators. At this stage, the query plan is also potentially ready to be run in parallel, as we can now parallelize the execution of each layer represented in a vector. This proves that the computation of Declare Clauses can be reduced into an embarrassingly parallel problem, as the layered execution guarantees that no thread communication needs to happen, and that multiple threads could access contemporary the partial results associated to the immediately-descendant operators. \texttt{\color{red}[TODO: link to the infographic picture, continue the use case example. Potentially expand the description if something is not self-evident from the pictures]}
